{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Untitled1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MaherABBASSI/Dog_rating_wrangling_Udacity/blob/master/Flower_resnet152.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "JfygemXDzwKX",
        "colab_type": "code",
        "outputId": "d6bc4963-c5d1-4f7d-d193-38d20fd936e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "cell_type": "code",
      "source": [
        "!wget 'https://www.dropbox.com/s/9tffplt24nanxnf/flowers_test.zip?dl=0'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-01-01 09:02:55--  https://www.dropbox.com/s/9tffplt24nanxnf/flowers_test.zip?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.82.1, 2620:100:6032:1::a27d:5201\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.82.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/9tffplt24nanxnf/flowers_test.zip [following]\n",
            "--2019-01-01 09:02:56--  https://www.dropbox.com/s/raw/9tffplt24nanxnf/flowers_test.zip\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc01eaf091fb14278fc2713198ce.dl.dropboxusercontent.com/cd/0/inline/AYlGHJSe1rBHoLUh4Qu5Wn0rTJsLhEUZoXb2IaDwtuAnwKJpb2aeXKta6_08wX-XrP1vuFNita4ZX6qPRk1bgS-5pDWIjWeLmy3W1XkzSr0wNLRByxQfOMS2d9__tAfKobrMIq7bEi2miRuFQAb9MxgOw1GDEYLdUpAxQND2AWYKrGJ7KPz3wVxTL3snKOHQ1Zg/file [following]\n",
            "--2019-01-01 09:02:56--  https://uc01eaf091fb14278fc2713198ce.dl.dropboxusercontent.com/cd/0/inline/AYlGHJSe1rBHoLUh4Qu5Wn0rTJsLhEUZoXb2IaDwtuAnwKJpb2aeXKta6_08wX-XrP1vuFNita4ZX6qPRk1bgS-5pDWIjWeLmy3W1XkzSr0wNLRByxQfOMS2d9__tAfKobrMIq7bEi2miRuFQAb9MxgOw1GDEYLdUpAxQND2AWYKrGJ7KPz3wVxTL3snKOHQ1Zg/file\n",
            "Resolving uc01eaf091fb14278fc2713198ce.dl.dropboxusercontent.com (uc01eaf091fb14278fc2713198ce.dl.dropboxusercontent.com)... 162.125.82.6, 2620:100:6032:6::a27d:5206\n",
            "Connecting to uc01eaf091fb14278fc2713198ce.dl.dropboxusercontent.com (uc01eaf091fb14278fc2713198ce.dl.dropboxusercontent.com)|162.125.82.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: /cd/0/inline2/AYnEmrYFeJ1t3XeAuu7oEEr_K7WKGh0uXFE60nnD99rtAhDjyHPUF68jNF5G6L9CO-7XF9frXY0BUJsVtVyVd7Jel6txPe8vAO70iuA6igS7n2veR_NF74lfishKF1KuEMlahxhLiDYmwuJloFm4WSyRIvzdfNYxFBR5vkeTL40EozF_E86fRwU30wbMeNQmogCTL5TjF4F4NkBscPg7j6QI-c_Ach4cYbL1U43-Ec2sKJUdKqee7V14KvgvOsh2lhta-_WNH_EjXGBEQX-Wb13PihlpicJBDH2iK8y9OdNsDlThpLuPPN6Or3LXBlwerjwvFmrOW-yFYy7v2yr56vkEBBPDwV_JQ8nwjvBeF1jJOUq_fQt2qXtzx0P0v8QNQ8ZJ0ssjkGWJakLPWdcAOEBlKrKqFeFnDHdv2FvV7mFUWBjj6tlnZ8uafWg81qWbafU/file [following]\n",
            "--2019-01-01 09:02:57--  https://uc01eaf091fb14278fc2713198ce.dl.dropboxusercontent.com/cd/0/inline2/AYnEmrYFeJ1t3XeAuu7oEEr_K7WKGh0uXFE60nnD99rtAhDjyHPUF68jNF5G6L9CO-7XF9frXY0BUJsVtVyVd7Jel6txPe8vAO70iuA6igS7n2veR_NF74lfishKF1KuEMlahxhLiDYmwuJloFm4WSyRIvzdfNYxFBR5vkeTL40EozF_E86fRwU30wbMeNQmogCTL5TjF4F4NkBscPg7j6QI-c_Ach4cYbL1U43-Ec2sKJUdKqee7V14KvgvOsh2lhta-_WNH_EjXGBEQX-Wb13PihlpicJBDH2iK8y9OdNsDlThpLuPPN6Or3LXBlwerjwvFmrOW-yFYy7v2yr56vkEBBPDwV_JQ8nwjvBeF1jJOUq_fQt2qXtzx0P0v8QNQ8ZJ0ssjkGWJakLPWdcAOEBlKrKqFeFnDHdv2FvV7mFUWBjj6tlnZ8uafWg81qWbafU/file\n",
            "Reusing existing connection to uc01eaf091fb14278fc2713198ce.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 381637980 (364M) [application/zip]\n",
            "Saving to: ‘flowers_test.zip?dl=0’\n",
            "\n",
            "flowers_test.zip?dl 100%[===================>] 363.96M  35.0MB/s    in 12s     \n",
            "\n",
            "2019-01-01 09:03:10 (31.0 MB/s) - ‘flowers_test.zip?dl=0’ saved [381637980/381637980]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IWomxPjQzx9_",
        "colab_type": "code",
        "outputId": "b8ea6ef7-6afb-4c13-f9a5-cc4bd0f9ce34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "!unzip 'flowers_test.zip?dl=0' -d 'flowers_test'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  flowers_test.zip?dl=0\n",
            "replace flowers_test/flowers_test/flower_data/test/1/image_06743.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AoFXi4f-qcEP",
        "colab_type": "code",
        "outputId": "9aa1a6f7-b6ec-4847-bee2-ce6e08c29a61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "cell_type": "code",
      "source": [
        "!wget 'https://www.dropbox.com/s/1axw0f86uw2gn9u/model_BN1.pt?dl=0'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-01-01 09:04:26--  https://www.dropbox.com/s/1axw0f86uw2gn9u/model_BN1.pt?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.82.1, 2620:100:6032:1::a27d:5201\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.82.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/1axw0f86uw2gn9u/model_BN1.pt [following]\n",
            "--2019-01-01 09:04:27--  https://www.dropbox.com/s/raw/1axw0f86uw2gn9u/model_BN1.pt\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uccee0524c41a264503ca1e0d04a.dl.dropboxusercontent.com/cd/0/inline/AYm-Zgom8lRluu2lvyn9fOZ_jg34QSkG-92X1WdrgjaJShnBIorc8t44D3UFKcZqftJKRqkb2iEXqy7tWRk_yl44xqqohnny42i-3PDBa6m9o6LyWjPgcnurSYKEwKUvX8ttzxqggJ14n21JdyIpybz8ZzDMvGvxkViT1VqsTtvJqj8lzhn05rbJvs7xtnTP1Xg/file [following]\n",
            "--2019-01-01 09:04:27--  https://uccee0524c41a264503ca1e0d04a.dl.dropboxusercontent.com/cd/0/inline/AYm-Zgom8lRluu2lvyn9fOZ_jg34QSkG-92X1WdrgjaJShnBIorc8t44D3UFKcZqftJKRqkb2iEXqy7tWRk_yl44xqqohnny42i-3PDBa6m9o6LyWjPgcnurSYKEwKUvX8ttzxqggJ14n21JdyIpybz8ZzDMvGvxkViT1VqsTtvJqj8lzhn05rbJvs7xtnTP1Xg/file\n",
            "Resolving uccee0524c41a264503ca1e0d04a.dl.dropboxusercontent.com (uccee0524c41a264503ca1e0d04a.dl.dropboxusercontent.com)... 162.125.82.6, 2620:100:6032:6::a27d:5206\n",
            "Connecting to uccee0524c41a264503ca1e0d04a.dl.dropboxusercontent.com (uccee0524c41a264503ca1e0d04a.dl.dropboxusercontent.com)|162.125.82.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: /cd/0/inline2/AYku5eOeCdoI5u9Lc1h26JzCTqj85tf1Jk3AVo7P5UmYnZSKjdhpQtH-hPEDtRNIBgnGrW5UnuYq3apmtZnYQxEFTibV3sg3HzxQfQ4yCc0w2OUY8rpJ_zXf3pZ6akhOwC7Uq_mAcWvsZLJZ-AX9tv-Aqzg7QaV7u4EHA-CWjHZhE6IJ7zPqHlf9axfA3bLNVSbcDn91bvP_nsSm5MzIWXEuIvUSxg2DSeJSjmt0bmxQsv6w2ZtXTAQLZY9gRqfupEmyLf-RBvlKqifu32Da0PQTFZPN0A1Qt3QRmFYp36lD96vph4ps9qc4n8oD5vwnX9xduxvoe0kYcguV613iytXVtBDyqfmyn0eNPgeEpI4jgYBAuSWvZjOavobU859Rf-38CZD_7UjkvHJ3RgyD3Yycn3kTtlckAWcbLqxbBsSNpFR0JTz_5dOQLNMz0FfauFA/file [following]\n",
            "--2019-01-01 09:04:28--  https://uccee0524c41a264503ca1e0d04a.dl.dropboxusercontent.com/cd/0/inline2/AYku5eOeCdoI5u9Lc1h26JzCTqj85tf1Jk3AVo7P5UmYnZSKjdhpQtH-hPEDtRNIBgnGrW5UnuYq3apmtZnYQxEFTibV3sg3HzxQfQ4yCc0w2OUY8rpJ_zXf3pZ6akhOwC7Uq_mAcWvsZLJZ-AX9tv-Aqzg7QaV7u4EHA-CWjHZhE6IJ7zPqHlf9axfA3bLNVSbcDn91bvP_nsSm5MzIWXEuIvUSxg2DSeJSjmt0bmxQsv6w2ZtXTAQLZY9gRqfupEmyLf-RBvlKqifu32Da0PQTFZPN0A1Qt3QRmFYp36lD96vph4ps9qc4n8oD5vwnX9xduxvoe0kYcguV613iytXVtBDyqfmyn0eNPgeEpI4jgYBAuSWvZjOavobU859Rf-38CZD_7UjkvHJ3RgyD3Yycn3kTtlckAWcbLqxbBsSNpFR0JTz_5dOQLNMz0FfauFA/file\n",
            "Reusing existing connection to uccee0524c41a264503ca1e0d04a.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 244039380 (233M) [application/octet-stream]\n",
            "Saving to: ‘model_BN1.pt?dl=0’\n",
            "\n",
            "model_BN1.pt?dl=0   100%[===================>] 232.73M  33.4MB/s    in 7.1s    \n",
            "\n",
            "2019-01-01 09:04:36 (32.6 MB/s) - ‘model_BN1.pt?dl=0’ saved [244039380/244039380]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tCENyxrlt1LR",
        "colab_type": "code",
        "outputId": "8b6f43dd-1683-49a6-a833-a38eb65ae2ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/cu90/torch-0.4.0-cp36-cp36m-linux_x86_64.whl torchvision"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tcmalloc: large alloc 1073750016 bytes == 0x5ceee000 @  0x7f04829682a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "b2-tyfXSt_k3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hbuNZS91uA-F",
        "colab_type": "code",
        "outputId": "14f0af31-8d76-4281-c1d3-445b6ada9703",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# check if CUDA is available\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "else:\n",
        "    print('CUDA is available!  Training on GPU ...')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA is available!  Training on GPU ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4SSfKdYHuMmU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# TODO: Define your transforms for the training and validation sets\n",
        "data_transforms = transforms.Compose([transforms.RandomResizedCrop(224), \n",
        "                                transforms.RandomHorizontalFlip(),\n",
        "                                transforms.RandomRotation(30), \n",
        "                                transforms.ToTensor(), \n",
        "                                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "# TODO: Load the datasets with ImageFolder\n",
        "train_data = datasets.ImageFolder(r'flowers_test/flowers_test/flower_data/train', transform = data_transforms)\n",
        "valid_data = datasets.ImageFolder(r'flowers_test/flowers_test/flower_data/valid', transform = data_transforms)\n",
        "\n",
        "# TODO: Using the image datasets and the trainforms, define the dataloaders\n",
        "batch_size = 20\n",
        "num_workers= 20\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, \n",
        "                                           num_workers=num_workers, shuffle=True)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=batch_size, \n",
        "                                          num_workers=num_workers, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_F9VlIXEv6Cm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open('cat_to_name.json', 'r') as f:\n",
        "    cat_to_name = json.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rZ4DEneev8pH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load the pretrained model from pytorch\n",
        "model = models.resnet152(pretrained=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IeSOJWVwok1m",
        "colab_type": "code",
        "outputId": "bc6f3c1b-cc2b-4370-a207-82b37cd9e233",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# define the CNN architecture\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # linear layer (2048 -> 1024)\n",
        "        self.fc1 = nn.Linear(2048, 1024)\n",
        "        self.batch1 = nn.BatchNorm1d(1024)\n",
        "        # linear layer (1024 -> 512)\n",
        "        self.fc2 = nn.Linear(1024, 512)\n",
        "        self.batch2 = nn.BatchNorm1d(512)\n",
        "        # linear layer (512 -> 102)\n",
        "        self.fc3 = nn.Linear(512, 102)\n",
        "        # dropout layer (p=0.25)\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        # add 1st hidden layer, with relu activation function\n",
        "        x = F.relu(self.batch1(self.fc1(x)))\n",
        "        # add dropout layer\n",
        "        x = self.dropout(x)\n",
        "        # add 2nd hidden layer, with relu activation function\n",
        "        x = F.relu(self.batch2(self.fc2(x)))\n",
        "        # add dropout layer\n",
        "        x = self.dropout(x)\n",
        "        # add 3d hidden layer\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# create a complete CNN\n",
        "sub_model = Net()\n",
        "print(sub_model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=2048, out_features=1024, bias=True)\n",
            "  (batch1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
            "  (batch2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (fc3): Linear(in_features=512, out_features=102, bias=True)\n",
            "  (dropout): Dropout(p=0.25)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WXLv-kaCwUGj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.fc = sub_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pI58vSSm1eDP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for name, param in model.named_parameters():\n",
        "  param.requires_grad = False\n",
        "\n",
        "for name, param in model.fc.named_parameters():\n",
        "  param.requires_grad = True\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MDyulBPQ9nuQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for name, param in model.named_parameters():\n",
        "  param.requires_grad = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kIPINy9EwZHa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "if train_on_gpu:\n",
        "    model.cuda()\n",
        "    \n",
        "# specify loss function (categorical cross-entropy)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "optimizer = optim.SGD(model.fc.parameters(),  lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z1QyLiNI-BAd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "if train_on_gpu:\n",
        "    model.cuda()\n",
        "    \n",
        "# specify loss function (categorical cross-entropy)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(),  lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1O6Bmqj3k2P7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pretrained_dict = torch.load('model_BN1.pt?dl=0', map_location=lambda storage, loc: storage)\n",
        "model_dict = model.state_dict()\n",
        "\n",
        "# 1. filter out unnecessary keys\n",
        "pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
        "# 2. overwrite entries in the existing state dict\n",
        "model_dict.update(pretrained_dict) \n",
        "# 3. load the new state dict\n",
        "model.load_state_dict(pretrained_dict)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lyqZmY9e0mhZ",
        "colab_type": "code",
        "outputId": "e647dfdf-d9c7-46e0-913b-7733a50edcac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install Pillow==4.1.1\n",
        "!pip install image"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Pillow==4.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/e5/88b3d60924a3f8476fa74ec086f5fbaba56dd6cee0d82845f883b6b6dd18/Pillow-4.1.1-cp36-cp36m-manylinux1_x86_64.whl (5.7MB)\n",
            "\u001b[K    100% |████████████████████████████████| 5.7MB 7.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow==4.1.1) (0.46)\n",
            "Installing collected packages: Pillow\n",
            "  Found existing installation: Pillow 5.3.0\n",
            "    Uninstalling Pillow-5.3.0:\n",
            "      Successfully uninstalled Pillow-5.3.0\n",
            "Successfully installed Pillow-4.1.1\n",
            "Requirement already satisfied: image in /usr/local/lib/python3.6/dist-packages (1.5.27)\n",
            "Requirement already satisfied: django in /usr/local/lib/python3.6/dist-packages (from image) (2.1.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from image) (4.1.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from django->image) (2018.7)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->image) (0.46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4jmhloHawyGv",
        "colab_type": "code",
        "outputId": "94135306-d3b1-4c85-9a2e-27d654189505",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "cell_type": "code",
      "source": [
        "# number of epochs to train the model\n",
        "n_epochs = 200\n",
        "\n",
        "valid_loss_min = np.Inf # track change in validation loss\n",
        "\n",
        "for epoch in range(1, n_epochs+1):\n",
        "\n",
        "    # keep track of training and validation loss\n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "    \n",
        "    ###################\n",
        "    # train the model #\n",
        "    ###################\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        # move tensors to GPU if CUDA is available\n",
        "        if train_on_gpu:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        # clear the gradients of all optimized variables\n",
        "        optimizer.zero_grad()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the mode\n",
        "        output = model(data)\n",
        "        # calculate the batch loss\n",
        "        loss = criterion(output, target)\n",
        "        # backward pass: compute gradient of the loss with respect to model parameters\n",
        "        loss.backward()\n",
        "        # perform a single optimization step (parameter update)\n",
        "        optimizer.step()\n",
        "        # update training loss\n",
        "        train_loss += loss.item()*data.size(0)\n",
        "        \n",
        "    ######################    \n",
        "    # validate the model #\n",
        "    ######################\n",
        "    model.eval()\n",
        "    for batch_idx, (data, target) in enumerate(valid_loader):\n",
        "        # move tensors to GPU if CUDA is available\n",
        "        if train_on_gpu:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(data)\n",
        "        # calculate the batch loss\n",
        "        loss = criterion(output, target)\n",
        "        # update average validation loss \n",
        "        valid_loss += loss.item()*data.size(0)\n",
        "    \n",
        "    # calculate average losses\n",
        "    train_loss = train_loss/len(train_loader.dataset)\n",
        "    valid_loss = valid_loss/len(valid_loader.dataset)\n",
        "    \n",
        "    if (batch_idx+1) % 100 == 0:\n",
        "        scheduler.step()\n",
        "    # print training/validation statistics \n",
        "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "        epoch, train_loss, valid_loss))\n",
        "    \n",
        "    # save model if validation loss has decreased\n",
        "    if valid_loss <= valid_loss_min:\n",
        "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "        valid_loss_min,\n",
        "        valid_loss))\n",
        "        torch.save(model.state_dict(), 'model.pt')\n",
        "        valid_loss_min = valid_loss"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss: 0.092728 \tValidation Loss: 0.162830\n",
            "Validation loss decreased (inf --> 0.162830).  Saving model ...\n",
            "Epoch: 2 \tTraining Loss: 0.088015 \tValidation Loss: 0.138633\n",
            "Validation loss decreased (0.162830 --> 0.138633).  Saving model ...\n",
            "Epoch: 3 \tTraining Loss: 0.115994 \tValidation Loss: 0.147121\n",
            "Epoch: 4 \tTraining Loss: 0.106368 \tValidation Loss: 0.131873\n",
            "Validation loss decreased (0.138633 --> 0.131873).  Saving model ...\n",
            "Epoch: 5 \tTraining Loss: 0.106164 \tValidation Loss: 0.140383\n",
            "Epoch: 6 \tTraining Loss: 0.095541 \tValidation Loss: 0.165790\n",
            "Epoch: 7 \tTraining Loss: 0.091531 \tValidation Loss: 0.154355\n",
            "Epoch: 8 \tTraining Loss: 0.100580 \tValidation Loss: 0.147570\n",
            "Epoch: 9 \tTraining Loss: 0.095488 \tValidation Loss: 0.131907\n",
            "Epoch: 10 \tTraining Loss: 0.086136 \tValidation Loss: 0.131151\n",
            "Validation loss decreased (0.131873 --> 0.131151).  Saving model ...\n",
            "Epoch: 11 \tTraining Loss: 0.087890 \tValidation Loss: 0.129441\n",
            "Validation loss decreased (0.131151 --> 0.129441).  Saving model ...\n",
            "Epoch: 12 \tTraining Loss: 0.097785 \tValidation Loss: 0.135808\n",
            "Epoch: 13 \tTraining Loss: 0.095435 \tValidation Loss: 0.171520\n",
            "Epoch: 14 \tTraining Loss: 0.089826 \tValidation Loss: 0.129895\n",
            "Epoch: 15 \tTraining Loss: 0.092446 \tValidation Loss: 0.163449\n",
            "Epoch: 16 \tTraining Loss: 0.086329 \tValidation Loss: 0.126560\n",
            "Validation loss decreased (0.129441 --> 0.126560).  Saving model ...\n",
            "Epoch: 17 \tTraining Loss: 0.083514 \tValidation Loss: 0.137454\n",
            "Epoch: 18 \tTraining Loss: 0.095258 \tValidation Loss: 0.120620\n",
            "Validation loss decreased (0.126560 --> 0.120620).  Saving model ...\n",
            "Epoch: 19 \tTraining Loss: 0.091866 \tValidation Loss: 0.133484\n",
            "Epoch: 20 \tTraining Loss: 0.081169 \tValidation Loss: 0.148639\n",
            "Epoch: 21 \tTraining Loss: 0.085172 \tValidation Loss: 0.152820\n",
            "Epoch: 22 \tTraining Loss: 0.075028 \tValidation Loss: 0.154465\n",
            "Epoch: 23 \tTraining Loss: 0.085852 \tValidation Loss: 0.128046\n",
            "Epoch: 24 \tTraining Loss: 0.089544 \tValidation Loss: 0.164787\n",
            "Epoch: 25 \tTraining Loss: 0.065897 \tValidation Loss: 0.138021\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "69qGiYoSrVuI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}